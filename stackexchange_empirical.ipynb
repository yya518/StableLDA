{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7865cd61",
   "metadata": {},
   "source": [
    "## This notebook reproduces the results reported in Section 6.1 \"Empirical study: online knowledge community\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af900d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.discrete.discrete_model import Poisson\n",
    "\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e2c2f",
   "metadata": {},
   "source": [
    "#### Read in original dataset, the stackexchange dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b62fff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>post</th>\n",
       "      <th>answer</th>\n",
       "      <th>post_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>post_idx</th>\n",
       "      <th>answer_idx</th>\n",
       "      <th>logwords</th>\n",
       "      <th>dummy</th>\n",
       "      <th>AnswerHepfulness</th>\n",
       "      <th>QuestionHelpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In Darksiders 3 there are many enemies who ...</td>\n",
       "      <td>&lt;p&gt;The ways I found to beat blocking enemies, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In Level 2-3 of Super Mario 3D Land, by Mar...</td>\n",
       "      <td>&lt;p&gt;You need to hit it with your Tanooki's suit...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;All MMO's have massive amounts of data in d...</td>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;It's also a question of cost and predictabi...</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>1</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;They may need to deploy updates to binaries...</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>1</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               post  \\\n",
       "0   gaming  <p>In Darksiders 3 there are many enemies who ...   \n",
       "1   gaming  <p>In Level 2-3 of Super Mario 3D Land, by Mar...   \n",
       "2   gaming  <p>In massively multiplayer games, the servers...   \n",
       "3   gaming  <p>In massively multiplayer games, the servers...   \n",
       "4   gaming  <p>In massively multiplayer games, the servers...   \n",
       "\n",
       "                                              answer  post_score  \\\n",
       "0  <p>The ways I found to beat blocking enemies, ...           0   \n",
       "1  <p>You need to hit it with your Tanooki's suit...           4   \n",
       "2  <p>All MMO's have massive amounts of data in d...          46   \n",
       "3  <p>It's also a question of cost and predictabi...          46   \n",
       "4  <p>They may need to deploy updates to binaries...          46   \n",
       "\n",
       "   answer_score  Sequence  post_idx  answer_idx  logwords  dummy  \\\n",
       "0             0       1.0         0           1  3.433987      0   \n",
       "1             7       1.0         2           3  1.791759      1   \n",
       "2            43       1.0         4           5  3.401197      1   \n",
       "3            21       2.0         4           6  4.897840      1   \n",
       "4             6       3.0         4           7  3.367296      1   \n",
       "\n",
       "   AnswerHepfulness  QuestionHelpfulness  \n",
       "0          0.000000             0.000000  \n",
       "1          1.945910             1.386294  \n",
       "2          3.761200             3.828641  \n",
       "3          3.044522             3.828641  \n",
       "4          1.791759             3.828641  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/stackexchange.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef45a",
   "metadata": {},
   "source": [
    "#### Total number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae279ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51647"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.post.unique()) + len(df.answer.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5056a",
   "metadata": {},
   "source": [
    "#### Read in data (the bow file and vocab file) for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d18e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "with io.open('data/stackexchange.bow', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read().splitlines()\n",
    "\n",
    "vocabs = []\n",
    "with io.open('data/stackexchange.vocab', 'r', encoding='utf-8') as f:\n",
    "    vocabs = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f54dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "288c3f32",
   "metadata": {},
   "source": [
    "#### using StableLDA to infer topic vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3b2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stability import *\n",
    "from stablelda import StableLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94122a83",
   "metadata": {},
   "source": [
    "first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58e3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_file = 'data/stackexchange.bow'\n",
    "vocab_file = 'data/stackexchange.vocab'\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 5000\n",
    "alpha, beta, eta = 1, 0.01, 1000\n",
    "epochs = 2\n",
    "rand_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79befe9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first model\n",
    "output_dir = 'data/output/'\n",
    "stablelda = StableLDA(num_topics, num_words, alpha, beta, eta, rand_seed, output_dir )\n",
    "stablelda.train(bow_file, vocab_file, epochs)\n",
    "\n",
    "docs, vocab, theta, phi = load_topic_model_results(bow_file, vocab_file,\n",
    "                                                     output_dir+'theta.dat', output_dir+'phi.dat')\n",
    "tm = TopicModel(num_topics, theta, phi, docs, vocab)\n",
    "\n",
    "tm.print_top_n_words(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8d5ce",
   "metadata": {},
   "source": [
    "generate QASimilarity variable, which is the cosine similarity between question and answer topic vector. Note: This variable can be quite unstable if it were generated by LDA model due to its instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580b534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stablelda_sim'] = df.apply(lambda x:1-cosine(theta[x['post_idx']], theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88212b",
   "metadata": {},
   "source": [
    "run regression: \n",
    "\n",
    "AnswerHelpfulness = $\\beta_0$ + $\\beta_1$StableLDASimilarity + $\\beta_2$Sequence + $\\beta_3$QuestionHelpfulness + $\\beta_4$log(words) + $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e78ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4246.\n",
      "Date:                Tue, 30 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        16:09:16   Log-Likelihood:                -37809.\n",
      "No. Observations:               32899   AIC:                         7.563e+04\n",
      "Df Residuals:                   32894   BIC:                         7.567e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.2592      0.043     -6.100      0.000      -0.343      -0.176\n",
      "stablelda_sim           0.1784      0.043      4.165      0.000       0.094       0.262\n",
      "Sequence               -0.2155      0.003    -75.509      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.441      0.000       0.464       0.481\n",
      "logwords                0.2213      0.005     45.757      0.000       0.212       0.231\n",
      "==============================================================================\n",
      "Omnibus:                      321.161   Durbin-Watson:                   1.936\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              320.376\n",
      "Skew:                           0.226   Prob(JB):                     2.70e-70\n",
      "Kurtosis:                       2.830   Cond. No.                         63.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483d1c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453723\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 30 Aug 2022   Pseudo R-squ.:                  0.1415\n",
      "Time:                        16:09:16   Log-Likelihood:                -14927.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.8991      0.149     -6.029      0.000      -1.191      -0.607\n",
      "stablelda_sim           0.3992      0.151      2.636      0.008       0.102       0.696\n",
      "Sequence               -0.5231      0.011    -47.468      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5386      0.016     33.425      0.000       0.507       0.570\n",
      "logwords                0.6715      0.018     37.955      0.000       0.637       0.706\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcdcc3",
   "metadata": {},
   "source": [
    "Note that due to stochasticity, the regression result (effect size) may be different across runs. So the result is slightly different from that reported in Table I. Stable LDA offers much more stable results than that of LDA, in terms of effect size and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd60a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.259*** -0.899***\n",
      "                    (0.043)   (0.149)  \n",
      "stablelda_sim       0.178***  0.399*** \n",
      "                    (0.043)   (0.151)  \n",
      "Sequence            -0.216*** -0.523***\n",
      "                    (0.003)   (0.011)  \n",
      "QuestionHelpfulness 0.472***  0.539*** \n",
      "                    (0.004)   (0.016)  \n",
      "logwords            0.221***  0.672*** \n",
      "                    (0.005)   (0.018)  \n",
      "AIC                 75628.    29864.   \n",
      "Log-Likelihood      -37809.   -14927.  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157b808",
   "metadata": {},
   "source": [
    "second run. We retrain a topic model, re-calculate the QASimilarity variable, and re-run the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97b961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second model\n",
    "output_dir = 'data/output/'\n",
    "random_seed = 24\n",
    "stablelda = StableLDA(num_topics, num_words, alpha, beta, eta, rand_seed, output_dir )\n",
    "stablelda.train(bow_file, vocab_file, epochs)\n",
    "\n",
    "docs, vocab, theta, phi = load_topic_model_results(bow_file, vocab_file,\n",
    "                                                     output_dir+'theta.dat', output_dir+'phi.dat')\n",
    "tm = TopicModel(num_topics, theta, phi, docs, vocab)\n",
    "\n",
    "tm.print_top_n_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312fd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stablelda_sim'] = df.apply(lambda x:1-cosine(theta[x['post_idx']], theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aff688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4245.\n",
      "Date:                Tue, 30 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        16:12:16   Log-Likelihood:                -37809.\n",
      "No. Observations:               32899   AIC:                         7.563e+04\n",
      "Df Residuals:                   32894   BIC:                         7.567e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.2567      0.042     -6.072      0.000      -0.340      -0.174\n",
      "stablelda_sim           0.1749      0.042      4.125      0.000       0.092       0.258\n",
      "Sequence               -0.2155      0.003    -75.489      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.442      0.000       0.464       0.481\n",
      "logwords                0.2214      0.005     45.660      0.000       0.212       0.231\n",
      "==============================================================================\n",
      "Omnibus:                      322.033   Durbin-Watson:                   1.936\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              321.430\n",
      "Skew:                           0.227   Prob(JB):                     1.59e-70\n",
      "Kurtosis:                       2.831   Cond. No.                         62.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## linear regression\n",
    "y, X = dmatrices('AnswerHepfulness ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037498a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453709\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 30 Aug 2022   Pseudo R-squ.:                  0.1416\n",
      "Time:                        16:12:16   Log-Likelihood:                -14927.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.9206      0.148     -6.201      0.000      -1.212      -0.630\n",
      "stablelda_sim           0.4215      0.150      2.807      0.005       0.127       0.716\n",
      "Sequence               -0.5231      0.011    -47.466      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5387      0.016     33.428      0.000       0.507       0.570\n",
      "logwords                0.6729      0.018     37.932      0.000       0.638       0.708\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "## logit regression\n",
    "y, X = dmatrices('dummy ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ff2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.257*** -0.921***\n",
      "                    (0.042)   (0.148)  \n",
      "stablelda_sim       0.175***  0.422*** \n",
      "                    (0.042)   (0.150)  \n",
      "Sequence            -0.215*** -0.523***\n",
      "                    (0.003)   (0.011)  \n",
      "QuestionHelpfulness 0.472***  0.539*** \n",
      "                    (0.004)   (0.016)  \n",
      "logwords            0.221***  0.673*** \n",
      "                    (0.005)   (0.018)  \n",
      "AIC                 75628.    29863.   \n",
      "Log-Likelihood      -37809.   -14927.  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2407a5b",
   "metadata": {},
   "source": [
    "#### takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face6a08",
   "metadata": {},
   "source": [
    "In the first linear regression model, the coefficient of QASimilarity (stablelda_sim) is 0.1784, and pvalue is 0.000\n",
    "\n",
    "In the second linear regression model, the coefficient of QASimilarity (stablelda_sim) is 0.1749, and pvalue is 0.000\n",
    "\n",
    "In the first logit regression model, the coefficient of QASimilarity (stablelda_sim) is 0.3992, and pvalue is 0.008\n",
    "\n",
    "In the second logit regression model, the coefficient of QASimilarity (stablelda_sim) is 0.4215, and pvalue is 0.005\n",
    "\n",
    "The effect size and pvalue is stable. To reproduce results in Figure 4 and Figure 5, please run Stable LDA 10 times, save the QASimilarity and regression results, and examine the effect size and p-value of QASimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24879a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f9911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1bc9cf2",
   "metadata": {},
   "source": [
    "#### using LDA to infer topic vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8797ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02b98208",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensimcorpus = pickle.load( open('data/stackexchange.gaming.corpus.gensim', 'rb'))\n",
    "id2word = pickle.load( open('data/stackexchange.gaming.id2word.gensim', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab111c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51647, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gensimcorpus), len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a03bb",
   "metadata": {},
   "source": [
    "LDA first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "666b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(gensimcorpus, num_topics= num_topics, alpha='symmetric', id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9826667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_theta = []\n",
    "for bow in gensimcorpus:\n",
    "    prob = [ i[1] for i in lda_model.get_document_topics(bow, minimum_probability=0)]\n",
    "    lda_theta.append(prob)\n",
    "df['lda_sim'] = df.apply(lambda x:1-cosine(lda_theta[x['post_idx']], lda_theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60c77b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4239.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:59:35   Log-Likelihood:                -37818.\n",
      "No. Observations:               32899   AIC:                         7.565e+04\n",
      "Df Residuals:                   32894   BIC:                         7.569e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.0975      0.017     -5.644      0.000      -0.131      -0.064\n",
      "lda_sim                 0.0029      0.026      0.112      0.911      -0.048       0.054\n",
      "Sequence               -0.2158      0.003    -75.587      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.399      0.000       0.464       0.481\n",
      "logwords                0.2143      0.005     47.271      0.000       0.205       0.223\n",
      "==============================================================================\n",
      "Omnibus:                      323.846   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              322.757\n",
      "Skew:                           0.227   Prob(JB):                     8.21e-71\n",
      "Kurtosis:                       2.828   Cond. No.                         27.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8d1222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453824\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 06 Sep 2022   Pseudo R-squ.:                  0.1413\n",
      "Time:                        10:59:36   Log-Likelihood:                -14930.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.5329      0.058     -9.237      0.000      -0.646      -0.420\n",
      "lda_sim                -0.0471      0.088     -0.533      0.594      -0.220       0.126\n",
      "Sequence               -0.5234      0.011    -47.494      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5378      0.016     33.393      0.000       0.506       0.569\n",
      "logwords                0.6557      0.017     39.488      0.000       0.623       0.688\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec89087",
   "metadata": {},
   "source": [
    "LDA second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adbb6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(gensimcorpus, num_topics= num_topics, alpha='symmetric', id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f963465",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_theta = []\n",
    "for bow in gensimcorpus:\n",
    "    prob = [ i[1] for i in lda_model.get_document_topics(bow, minimum_probability=0)]\n",
    "    lda_theta.append(prob)\n",
    "df['lda_sim'] = df.apply(lambda x:1-cosine(lda_theta[x['post_idx']], lda_theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "873e2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4239.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:56:32   Log-Likelihood:                -37817.\n",
      "No. Observations:               32899   AIC:                         7.564e+04\n",
      "Df Residuals:                   32894   BIC:                         7.569e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.0992      0.017     -5.738      0.000      -0.133      -0.065\n",
      "lda_sim                 0.0252      0.027      0.936      0.349      -0.028       0.078\n",
      "Sequence               -0.2157      0.003    -75.582      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.396      0.000       0.464       0.481\n",
      "logwords                0.2143      0.005     47.274      0.000       0.205       0.223\n",
      "==============================================================================\n",
      "Omnibus:                      323.723   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              322.689\n",
      "Skew:                           0.227   Prob(JB):                     8.49e-71\n",
      "Kurtosis:                       2.828   Cond. No.                         28.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6894939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453726\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 06 Sep 2022   Pseudo R-squ.:                  0.1415\n",
      "Time:                        10:56:32   Log-Likelihood:                -14927.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.5193      0.058     -9.004      0.000      -0.632      -0.406\n",
      "lda_sim                -0.2347      0.090     -2.610      0.009      -0.411      -0.058\n",
      "Sequence               -0.5237      0.011    -47.498      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5379      0.016     33.396      0.000       0.506       0.569\n",
      "logwords                0.6557      0.017     39.484      0.000       0.623       0.688\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559cbb2",
   "metadata": {},
   "source": [
    "#### takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5becdc0b",
   "metadata": {},
   "source": [
    "In the first linear regression model, the coefficient of QASimilarity (lda_sim) is 0.0029, and pvalue is 0.991\n",
    "\n",
    "In the second linear regression model, the coefficient of QASimilarity (lda_sim) is 0.0252, and pvalue is 0.349\n",
    "\n",
    "In the first logit regression model, the coefficient of QASimilarity (lda_sim) is  -0.0471, and pvalue is 0.594 \n",
    "\n",
    "In the second logit regression model, the coefficient of QASimilarity (lda_sim) is -0.2347, and pvalue is 0.009\n",
    "\n",
    "The effect size and pvalue is unstable. Using Logit regression, the variable\\'s estimation is insignificant in the first run, but becomes significanly negative in the second run.\n",
    "\n",
    "This is the problem  using LDA for variable generation in regression analysis -- sometimes you get significant results but sometimes you get completely opposite results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cdf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ee9976",
   "metadata": {},
   "source": [
    "#### We conduct robustness check using TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25342d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ab7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68647695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfsim = []\n",
    "for idx, row in df.iterrows():\n",
    "    post_tfidf = X[row.post_idx].todense()\n",
    "    answer_tfidf = X[row.answer_idx].todense()\n",
    "    tfidfsim.append( 1-cosine(post_tfidf, answer_tfidf) )\n",
    "df['tfidfsim'] = pd.Series(list(tfidfsim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b590e",
   "metadata": {},
   "source": [
    "run regression to examine the relationship between QA similarity and answer helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d03e8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.342\n",
      "Model:                            OLS   Adj. R-squared:                  0.342\n",
      "Method:                 Least Squares   F-statistic:                     4267.\n",
      "Date:                Sat, 27 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        15:03:36   Log-Likelihood:                -37780.\n",
      "No. Observations:               32898   AIC:                         7.557e+04\n",
      "Df Residuals:                   32893   BIC:                         7.561e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.1350      0.018     -7.626      0.000      -0.170      -0.100\n",
      "tfidfsim                0.2017      0.024      8.524      0.000       0.155       0.248\n",
      "Sequence               -0.2130      0.003    -74.209      0.000      -0.219      -0.207\n",
      "QuestionHelpfulness     0.4732      0.004    109.719      0.000       0.465       0.482\n",
      "logwords                0.2068      0.005     44.829      0.000       0.198       0.216\n",
      "==============================================================================\n",
      "Omnibus:                      321.094   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              319.622\n",
      "Skew:                           0.225   Prob(JB):                     3.94e-70\n",
      "Kurtosis:                       2.826   Cond. No.                         25.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('AnswerHepfulness ~ tfidfsim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17dde146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453120\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32898\n",
      "Model:                          Logit   Df Residuals:                    32893\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 27 Aug 2022   Pseudo R-squ.:                  0.1427\n",
      "Time:                        15:03:42   Log-Likelihood:                -14907.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.6344      0.059    -10.738      0.000      -0.750      -0.519\n",
      "tfidfsim                0.5499      0.082      6.698      0.000       0.389       0.711\n",
      "Sequence               -0.5159      0.011    -46.666      0.000      -0.538      -0.494\n",
      "QuestionHelpfulness     0.5417      0.016     33.580      0.000       0.510       0.573\n",
      "logwords                0.6345      0.017     37.556      0.000       0.601       0.668\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ tfidfsim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24050044",
   "metadata": {},
   "source": [
    "reproduce Table H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a281e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.135*** -0.634***\n",
      "                    (0.018)   (0.059)  \n",
      "tfidfsim            0.202***  0.550*** \n",
      "                    (0.024)   (0.082)  \n",
      "Sequence            -0.213*** -0.516***\n",
      "                    (0.003)   (0.011)  \n",
      "QuestionHelpfulness 0.473***  0.542*** \n",
      "                    (0.004)   (0.016)  \n",
      "logwords            0.207***  0.634*** \n",
      "                    (0.005)   (0.017)  \n",
      "AIC                 75571.    29823.   \n",
      "Log-Likelihood      -37780.   -14907.  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject2",
   "language": "python",
   "name": "myproject2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
